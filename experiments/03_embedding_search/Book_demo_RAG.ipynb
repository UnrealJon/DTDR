{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572a1983-45cc-44a9-b591-439dd9df85c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\python_install\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "G:\\python_install\\Lib\\site-packages\\transformers\\utils\\hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books directory: G:\\train_jw\\books\n",
      "Found .txt books: 6\n",
      "First few: ['books\\\\alice_in_wonderland.txt', 'books\\\\dracula.txt', 'books\\\\frankenstein.txt']\n",
      "  alice_in_wonderland.txt: 137 passages\n",
      "  dracula.txt: 250 passages\n",
      "  frankenstein.txt: 250 passages\n",
      "  moby_dick.txt: 250 passages\n",
      "  pride_and_prejudice.txt: 250 passages\n",
      "  sherlock_holmes.txt: 250 passages\n",
      "Total passages: 1387\n",
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 22/22 [00:01<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: (1387, 384)  time=1.4s\n",
      "DTDR built: qcoef=(1387, 512) dtype=int8 scales=(1387, 32) d_h=512 blocks=32\n",
      "\n",
      "RAG retrieval metrics (clean):\n",
      "{'mode': 'clean', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "\n",
      "RAG metrics under dropout corruption:\n",
      "0.0 {'mode': 'dropout_0.0', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.01 {'mode': 'dropout_0.01', 'K': 8.0, 'mean_overlap_vs_float': 0.9375, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.05 {'mode': 'dropout_0.05', 'K': 8.0, 'mean_overlap_vs_float': 0.8541666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.1 {'mode': 'dropout_0.1', 'K': 8.0, 'mean_overlap_vs_float': 0.75, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.2 {'mode': 'dropout_0.2', 'K': 8.0, 'mean_overlap_vs_float': 0.7708333333333334, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "\n",
      "RAG metrics under block-loss corruption:\n",
      "0.0 {'mode': 'blockloss_0.0', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.01 {'mode': 'blockloss_0.01', 'K': 8.0, 'mean_overlap_vs_float': 0.9375, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.05 {'mode': 'blockloss_0.05', 'K': 8.0, 'mean_overlap_vs_float': 0.9375, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.1 {'mode': 'blockloss_0.1', 'K': 8.0, 'mean_overlap_vs_float': 0.875, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.2 {'mode': 'blockloss_0.2', 'K': 8.0, 'mean_overlap_vs_float': 0.8541666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "\n",
      "==========================================================================================\n",
      "QUESTION: Who is the White Rabbit and what is he doing?\n",
      "Expected source: alice_in_wonderland.txt  | Anchors: ['white rabbit', 'rabbit']\n",
      "------------------------------------------------------------------------------------------\n",
      " 1. alice_in_wonderland.txt [chunk 30]\n",
      "n a melancholy tone. “Nobody seems to like her, down here, and I’m sure she’s the best cat in the world! Oh, my dear Dinah! I wonder if I shall ever see you any more!” And here poor Alice began to cry again, for she felt very lonely and low-spirited. In a …\n",
      "\n",
      " 2. alice_in_wonderland.txt [chunk 85]\n",
      "“That’s right!” shouted the Queen. “Can you play croquet?” The soldiers were silent, and looked at Alice, as the question was evidently meant for her. “Yes!” shouted Alice. “Come on, then!” roared the Queen, and Alice joined the procession, wondering very …\n",
      "\n",
      " 3. alice_in_wonderland.txt [chunk 5]\n",
      "ither question, it didn’t much matter which way she put it. She felt that she was dozing off, and had just begun to dream that she was walking hand in hand with Dinah, and saying to her very earnestly, “Now, Dinah, tell me the truth: did you ever eat a bat?” …\n",
      "\n",
      " 4. alice_in_wonderland.txt [chunk 13]\n",
      "hing half down the hall. After a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming. It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large …\n",
      "\n",
      " 5. alice_in_wonderland.txt [chunk 118]\n",
      "the jurors had a pencil that squeaked. This of course, Alice could _not_ stand, and she went round the court and got behind him, and very soon found an opportunity of taking it away. She did it so quickly that the poor little juror (it was Bill, the Lizard) …\n",
      "\n",
      "RAG PROMPT (example):\n",
      "------------------------------------------------------------------------------------------\n",
      "Question: Who is the White Rabbit and what is he doing?\n",
      "Context:\n",
      " n a melancholy tone. “Nobody seems to like her, down here, and I’m sure she’s the best cat in the world! Oh, my dear Dinah! I wonder if I shall ever see you any more!” And here poor Alice began to cry again, for she felt very lonely and low-spirited. In a little while, however, she again heard a little pattering of footsteps in the distance, and she looked up eagerly, half hoping that the Mouse had changed his mind, and was coming back to finish his story. CHAPTER IV. The Rabbit Sends in a Little Bill It was the White Rabbit, trotting slowly back again, and looking anxiously about as it …\n",
      "\n",
      "==========================================================================================\n",
      "QUESTION: Who is the White Rabbit and what is he doing?\n",
      "Expected source: alice_in_wonderland.txt  | Anchors: ['white rabbit', 'rabbit']\n",
      "------------------------------------------------------------------------------------------\n",
      " 1. alice_in_wonderland.txt [chunk 85]\n",
      "“That’s right!” shouted the Queen. “Can you play croquet?” The soldiers were silent, and looked at Alice, as the question was evidently meant for her. “Yes!” shouted Alice. “Come on, then!” roared the Queen, and Alice joined the procession, wondering very …\n",
      "\n",
      " 2. alice_in_wonderland.txt [chunk 13]\n",
      "hing half down the hall. After a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming. It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large …\n",
      "\n",
      " 3. alice_in_wonderland.txt [chunk 30]\n",
      "n a melancholy tone. “Nobody seems to like her, down here, and I’m sure she’s the best cat in the world! Oh, my dear Dinah! I wonder if I shall ever see you any more!” And here poor Alice began to cry again, for she felt very lonely and low-spirited. In a …\n",
      "\n",
      " 4. alice_in_wonderland.txt [chunk 118]\n",
      "the jurors had a pencil that squeaked. This of course, Alice could _not_ stand, and she went round the court and got behind him, and very soon found an opportunity of taking it away. She did it so quickly that the poor little juror (it was Bill, the Lizard) …\n",
      "\n",
      " 5. alice_in_wonderland.txt [chunk 31]\n",
      "since her swim in the pool, and the great hall, with the glass table and the little door, had vanished completely. Very soon the Rabbit noticed Alice, as she went hunting about, and called out to her in an angry tone, “Why, Mary Ann, what _are_ you doing out …\n",
      "\n",
      "RAG PROMPT (example):\n",
      "------------------------------------------------------------------------------------------\n",
      "Question: Who is the White Rabbit and what is he doing?\n",
      "Context:\n",
      " “That’s right!” shouted the Queen. “Can you play croquet?” The soldiers were silent, and looked at Alice, as the question was evidently meant for her. “Yes!” shouted Alice. “Come on, then!” roared the Queen, and Alice joined the procession, wondering very much what would happen next. “It’s—it’s a very fine day!” said a timid voice at her side. She was walking by the White Rabbit, who was peeping anxiously into her face. “Very,” said Alice: “—where’s the Duchess?” “Hush! Hush!” said the Rabbit in a low, hurried tone. He looked anxiously over his shoulder as he spoke, and then raised himself …\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# DTDR-RAG Experiment (single cell)\n",
    "# Purpose: Demonstrate DTDR supports RAG-style retrieval (natural-language questions -> passage retrieval)\n",
    "#          directly in quantized transform domain, with graceful degradation under corruption.\n",
    "#\n",
    "# Requirements:\n",
    "#   pip install sentence-transformers scipy numpy\n",
    "#\n",
    "# Notes:\n",
    "# - Uses Project Gutenberg texts (public domain) for a realistic corpus.\n",
    "# - Evaluates retrieval quality using RAG-relevant proxies:\n",
    "#     (1) overlap with float embedding baseline,\n",
    "#     (2) \"book-hit@K\" against known source book for each question,\n",
    "#     (3) simple anchor-term hit-rate in retrieved context.\n",
    "# - Does NOT run an LLM (keeps the experiment self-contained and still patent-appropriate).\n",
    "\n",
    "import os, re, math, time, random, textwrap\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "from scipy.linalg import hadamard\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BOOKS_DIR = \"books\"\n",
    "os.makedirs(BOOKS_DIR, exist_ok=True)\n",
    "\n",
    "GUTENBERG = [\n",
    "    (\"alice_in_wonderland.txt\", \"https://www.gutenberg.org/cache/epub/11/pg11.txt\"),\n",
    "    (\"pride_and_prejudice.txt\", \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"),\n",
    "    (\"frankenstein.txt\", \"https://www.gutenberg.org/cache/epub/84/pg84.txt\"),\n",
    "    (\"moby_dick.txt\", \"https://www.gutenberg.org/cache/epub/2701/pg2701.txt\"),\n",
    "    (\"sherlock_holmes.txt\", \"https://www.gutenberg.org/cache/epub/1661/pg1661.txt\"),\n",
    "    (\"dracula.txt\", \"https://www.gutenberg.org/cache/epub/345/pg345.txt\"),\n",
    "]\n",
    "\n",
    "def download(url: str, path: str, timeout: int = 30) -> bool:\n",
    "    import urllib.request\n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
    "        with urllib.request.urlopen(req, timeout=timeout) as resp:\n",
    "            data = resp.read()\n",
    "        try:\n",
    "            txt = data.decode(\"utf-8\")\n",
    "        except UnicodeDecodeError:\n",
    "            txt = data.decode(\"latin-1\")\n",
    "        with open(path, \"w\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            f.write(txt)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Download failed: {url} ({e})\")\n",
    "        return False\n",
    "\n",
    "def read_text_file(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def clean_gutenberg(text: str) -> str:\n",
    "    start = re.search(r\"\\*\\*\\*\\s*START OF (THIS|THE) PROJECT GUTENBERG\", text, flags=re.IGNORECASE)\n",
    "    end   = re.search(r\"\\*\\*\\*\\s*END OF (THIS|THE) PROJECT GUTENBERG\", text, flags=re.IGNORECASE)\n",
    "    if start and end and start.end() < end.start():\n",
    "        text = text[start.end():end.start()]\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def chunk_text(text: str, chunk_chars: int = 1200, overlap: int = 150, min_len: int = 250) -> List[str]:\n",
    "    chunks = []\n",
    "    i, n = 0, len(text)\n",
    "    step = max(1, chunk_chars - overlap)\n",
    "    while i < n:\n",
    "        ch = text[i:i+chunk_chars].strip()\n",
    "        if len(ch) >= min_len:\n",
    "            chunks.append(ch)\n",
    "        i += step\n",
    "    return chunks\n",
    "\n",
    "# Download missing books\n",
    "print(\"Books directory:\", os.path.abspath(BOOKS_DIR))\n",
    "for fname, url in GUTENBERG:\n",
    "    path = os.path.join(BOOKS_DIR, fname)\n",
    "    if not os.path.exists(path) or os.path.getsize(path) < 2000:\n",
    "        print(\"Downloading:\", fname)\n",
    "        download(url, path)\n",
    "\n",
    "book_paths = [os.path.join(BOOKS_DIR, fn) for fn in os.listdir(BOOKS_DIR) if fn.lower().endswith(\".txt\")]\n",
    "book_paths.sort()\n",
    "print(\"Found .txt books:\", len(book_paths))\n",
    "print(\"First few:\", book_paths[:3])\n",
    "\n",
    "@dataclass\n",
    "class Passage:\n",
    "    book: str\n",
    "    idx: int\n",
    "    text: str\n",
    "\n",
    "def build_passages(book_paths: List[str], chunk_chars=1200, overlap=150,\n",
    "                   include_books=None, max_passages_per_book=250) -> List[Passage]:\n",
    "    passages: List[Passage] = []\n",
    "    for p in book_paths:\n",
    "        bn = os.path.basename(p)\n",
    "        if include_books is not None and bn not in include_books:\n",
    "            continue\n",
    "        raw = read_text_file(p)\n",
    "        txt = clean_gutenberg(raw)\n",
    "        chunks = chunk_text(txt, chunk_chars=chunk_chars, overlap=overlap, min_len=250)\n",
    "        chunks = chunks[:max_passages_per_book]\n",
    "        print(f\"  {bn}: {len(chunks)} passages\")\n",
    "        for i, ch in enumerate(chunks):\n",
    "            passages.append(Passage(book=bn, idx=i, text=ch))\n",
    "    return passages\n",
    "\n",
    "# Use only the core Gutenberg set (ignore demo books if present)\n",
    "include_books = {fn for fn, _ in GUTENBERG}\n",
    "passages = build_passages(book_paths, chunk_chars=1200, overlap=150,\n",
    "                          include_books=include_books, max_passages_per_book=250)\n",
    "assert len(passages) > 200, \"Too few passages; increase max_passages_per_book or add books.\"\n",
    "texts = [p.text for p in passages]\n",
    "books = [p.book for p in passages]\n",
    "print(\"Total passages:\", len(passages))\n",
    "\n",
    "# ---------- Embeddings ----------\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "print(\"Loading embedding model:\", MODEL_NAME)\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "t0 = time.time()\n",
    "emb = model.encode(texts, batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
    "emb = np.asarray(emb, dtype=np.float32)\n",
    "t1 = time.time()\n",
    "print(f\"Embeddings: {emb.shape}  time={t1-t0:.1f}s\")\n",
    "\n",
    "# ---------- DTDR build ----------\n",
    "def next_pow2(n: int) -> int:\n",
    "    return 1 if n <= 1 else 2 ** int(math.ceil(math.log2(n)))\n",
    "\n",
    "def make_hadamard(n: int) -> np.ndarray:\n",
    "    if n & (n-1) != 0:\n",
    "        raise ValueError(\"Hadamard size must be power of 2\")\n",
    "    H = hadamard(n).astype(np.float32)\n",
    "    H /= np.sqrt(n)\n",
    "    return H\n",
    "\n",
    "def pad_to_dh(X: np.ndarray, d_h: int) -> np.ndarray:\n",
    "    N, d = X.shape\n",
    "    if d == d_h:\n",
    "        return X\n",
    "    out = np.zeros((N, d_h), dtype=X.dtype)\n",
    "    out[:, :d] = X\n",
    "    return out\n",
    "\n",
    "def dt_transform(X: np.ndarray, H: np.ndarray) -> np.ndarray:\n",
    "    return X @ H.T\n",
    "\n",
    "def quantize_blockwise(U: np.ndarray, bits: int = 8, block: int = 16) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    N, D = U.shape\n",
    "    nblocks = (D + block - 1) // block\n",
    "    scales = np.zeros((N, nblocks), dtype=np.float32)\n",
    "    qdtype = np.int8\n",
    "    qmax = 127\n",
    "    q = np.zeros((N, D), dtype=qdtype)\n",
    "    for b in range(nblocks):\n",
    "        j0, j1 = b * block, min(D, (b + 1) * block)\n",
    "        chunk = U[:, j0:j1]\n",
    "        amax = np.max(np.abs(chunk), axis=1) + 1e-12\n",
    "        s = amax / qmax\n",
    "        scales[:, b] = s\n",
    "        q[:, j0:j1] = np.clip(np.round(chunk / s[:, None]), -qmax, qmax).astype(qdtype)\n",
    "    return q, scales\n",
    "\n",
    "BITS = 8\n",
    "BLOCK = 16  # << RAG experiment default: 16 (good graded block-loss behavior)\n",
    "N, d_in = emb.shape\n",
    "d_h = next_pow2(d_in)\n",
    "H = make_hadamard(d_h)\n",
    "U = dt_transform(pad_to_dh(emb, d_h), H)\n",
    "qcoef, scales = quantize_blockwise(U, bits=BITS, block=BLOCK)\n",
    "print(f\"DTDR built: qcoef={qcoef.shape} dtype={qcoef.dtype} scales={scales.shape} d_h={d_h} blocks={scales.shape[1]}\")\n",
    "\n",
    "def topk(a: np.ndarray, k: int) -> np.ndarray:\n",
    "    k = int(k)\n",
    "    if k >= a.shape[0]:\n",
    "        return np.argsort(-a)\n",
    "    idx = np.argpartition(-a, k)[:k]\n",
    "    return idx[np.argsort(-a[idx])]\n",
    "\n",
    "def float_scores(qemb: np.ndarray) -> np.ndarray:\n",
    "    return emb @ qemb.astype(np.float32)\n",
    "\n",
    "def dt_scores(qemb: np.ndarray, qcoef_eval: np.ndarray, scales_eval: np.ndarray) -> np.ndarray:\n",
    "    uq = dt_transform(pad_to_dh(qemb[None, :], d_h), H)[0]  # (d_h,)\n",
    "    qf = qcoef_eval.astype(np.float32)\n",
    "    sf = scales_eval.astype(np.float32)\n",
    "    out = np.zeros((qf.shape[0],), dtype=np.float32)\n",
    "    nblocks = sf.shape[1]\n",
    "    for b in range(nblocks):\n",
    "        j0, j1 = b * BLOCK, min(d_h, (b + 1) * BLOCK)\n",
    "        out += (qf[:, j0:j1] * uq[j0:j1]).sum(axis=1) * sf[:, b]\n",
    "    return out\n",
    "\n",
    "# ---------- RAG-style query set (known source book + anchors) ----------\n",
    "# Each item: (question, expected_book_filename, anchor_terms)\n",
    "# \"anchor_terms\" are a conservative proxy for context relevance (not a generation metric).\n",
    "RAG_QUERIES = [\n",
    "    (\"Who is the White Rabbit and what is he doing?\", \"alice_in_wonderland.txt\", [\"white rabbit\", \"rabbit\"]),\n",
    "    (\"What does Elizabeth think of Mr. Darcy early on?\", \"pride_and_prejudice.txt\", [\"darcy\", \"elizabeth\"]),\n",
    "    (\"Who created the creature and what was the consequence?\", \"frankenstein.txt\", [\"frankenstein\", \"creature\"]),\n",
    "    (\"What is Captain Ahab obsessed with?\", \"moby_dick.txt\", [\"ahab\", \"whale\"]),\n",
    "    (\"What is Sherlock Holmes known for in solving mysteries?\", \"sherlock_holmes.txt\", [\"holmes\", \"watson\"]),\n",
    "    (\"Who is Count Dracula and what is his nature?\", \"dracula.txt\", [\"dracula\", \"count\"]),\n",
    "]\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s.lower())\n",
    "\n",
    "norm_passages = [normalize_text(t) for t in texts]\n",
    "\n",
    "def book_hit_at_k(idxs: np.ndarray, expected_book: str) -> int:\n",
    "    return int(any(books[i] == expected_book for i in idxs))\n",
    "\n",
    "def anchor_hit_at_k(idxs: np.ndarray, anchors: List[str]) -> int:\n",
    "    # anchor hit if any retrieved passage contains any anchor substring\n",
    "    anchors_l = [a.lower() for a in anchors]\n",
    "    for i in idxs:\n",
    "        t = norm_passages[i]\n",
    "        if any(a in t for a in anchors_l):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def eval_rag(qcoef_eval: np.ndarray, scales_eval: np.ndarray, label: str, K: int = 8) -> Dict[str, float]:\n",
    "    K = min(K, len(passages))\n",
    "    overlaps, bookhits, anchorhits = [], [], []\n",
    "    for q, exp_book, anchors in RAG_QUERIES:\n",
    "        qemb = model.encode([q], normalize_embeddings=True)[0].astype(np.float32)\n",
    "        base = topk(float_scores(qemb), K)\n",
    "        dt   = topk(dt_scores(qemb, qcoef_eval, scales_eval), K)\n",
    "        overlaps.append(len(set(base.tolist()).intersection(set(dt.tolist()))) / len(base))\n",
    "        bookhits.append(book_hit_at_k(dt, exp_book))\n",
    "        anchorhits.append(anchor_hit_at_k(dt, anchors))\n",
    "    return {\n",
    "        \"mode\": label,\n",
    "        \"K\": float(K),\n",
    "        \"mean_overlap_vs_float\": float(np.mean(overlaps)),\n",
    "        \"book_hit_rate@K\": float(np.mean(bookhits)),\n",
    "        \"anchor_hit_rate@K\": float(np.mean(anchorhits)),\n",
    "    }\n",
    "\n",
    "print(\"\\nRAG retrieval metrics (clean):\")\n",
    "print(eval_rag(qcoef, scales, \"clean\", K=8))\n",
    "\n",
    "# ---------- Corruption ----------\n",
    "def corrupt_dropout(q: np.ndarray, drop_frac: float, seed: int = 123) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    out = q.copy()\n",
    "    mask = rng.random(out.shape) < drop_frac\n",
    "    out[mask] = 0\n",
    "    return out\n",
    "\n",
    "def corrupt_block_loss(q: np.ndarray, block_frac: float, seed: int = 123) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    out = q.copy()\n",
    "    Nn, D = out.shape\n",
    "    nblocks = (D + BLOCK - 1)//BLOCK\n",
    "    if block_frac <= 0:\n",
    "        return out\n",
    "    n_drop = max(1, int(math.ceil(block_frac * nblocks)))\n",
    "    drop_blocks = rng.choice(nblocks, size=min(nblocks, n_drop), replace=False)\n",
    "    for b in drop_blocks:\n",
    "        j0, j1 = b*BLOCK, min(D, (b+1)*BLOCK)\n",
    "        out[:, j0:j1] = 0\n",
    "    return out\n",
    "\n",
    "levels = [0.0, 0.01, 0.05, 0.10, 0.20]\n",
    "print(\"\\nRAG metrics under dropout corruption:\")\n",
    "for lvl in levels:\n",
    "    q2 = corrupt_dropout(qcoef, lvl, seed=SEED)\n",
    "    print(lvl, eval_rag(q2, scales, f\"dropout_{lvl}\", K=8))\n",
    "\n",
    "print(\"\\nRAG metrics under block-loss corruption:\")\n",
    "for lvl in levels:\n",
    "    q2 = corrupt_block_loss(qcoef, lvl, seed=SEED)\n",
    "    print(lvl, eval_rag(q2, scales, f\"blockloss_{lvl}\", K=8))\n",
    "\n",
    "# ---------- Show example RAG prompts (question + retrieved context) ----------\n",
    "def show_rag_example(question: str, expected_book: str, anchors: List[str], qcoef_eval=qcoef, scales_eval=scales, K: int = 5):\n",
    "    qemb = model.encode([question], normalize_embeddings=True)[0].astype(np.float32)\n",
    "    idx = topk(dt_scores(qemb, qcoef_eval, scales_eval), K)\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"QUESTION:\", question)\n",
    "    print(\"Expected source:\", expected_book, \" | Anchors:\", anchors)\n",
    "    print(\"-\"*90)\n",
    "    for r, i in enumerate(idx, 1):\n",
    "        ps = passages[i]\n",
    "        print(f\"{r:>2}. {ps.book} [chunk {ps.idx}]\")\n",
    "        print(textwrap.shorten(ps.text.replace(\"\\n\",\" \"), width=260, placeholder=\" …\"))\n",
    "        print()\n",
    "    # A minimal “RAG prompt” example\n",
    "    context = \"\\n\\n\".join([passages[i].text for i in idx[:min(3, len(idx))]])\n",
    "    print(\"RAG PROMPT (example):\")\n",
    "    print(\"-\"*90)\n",
    "    print(\"Question:\", question)\n",
    "    print(\"Context:\\n\", textwrap.shorten(context.replace(\"\\n\",\" \"), width=600, placeholder=\" …\"))\n",
    "\n",
    "# Show one clean example\n",
    "q0, exp0, anc0 = RAG_QUERIES[0]\n",
    "show_rag_example(q0, exp0, anc0, qcoef_eval=qcoef, scales_eval=scales, K=5)\n",
    "\n",
    "# Show the same example under heavier corruption (demonstrates graceful degradation in RAG setting)\n",
    "qcor = corrupt_dropout(qcoef, 0.10, seed=SEED)\n",
    "show_rag_example(q0, exp0, anc0, qcoef_eval=qcor, scales_eval=scales, K=5)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3546fe1-b82d-44ac-8ff5-6f06297ee1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
