\# Model Weights



This experiment requires access to the Mistral-7B base model weights,

which are \*\*not included\*\* in this repository.



\## Obtaining the Base Model



The base weights may be obtained from the official source:



\- Model: Mistral-7B

\- Provider: Mistral AI

\- Platform: Hugging Face



Users must agree to the original model license terms.



\## DTDR-INT8 Weights



The DTDR-INT8 representation used in this experiment is \*\*derived from

the base model\*\* using `generate\_dtdr\_weights.py`.



For reference, the derived DTDR representation has:



\- Approximate size: ~6.7â€“6.8 GB

\- Quantisation: INT8

\- Representation: structured orthogonal DTDR



No model weights are redistributed in this repository.



