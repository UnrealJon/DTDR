{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff7e7b38-42fb-4363-aabc-e8f16dbbc119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\python_install\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "G:\\python_install\\Lib\\site-packages\\transformers\\utils\\hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books directory: G:\\train_jw\\experiments\\books\n",
      "Downloading: alice_in_wonderland.txt\n",
      "Downloading: pride_and_prejudice.txt\n",
      "Downloading: frankenstein.txt\n",
      "Downloading: moby_dick.txt\n",
      "Downloading: sherlock_holmes.txt\n",
      "Downloading: dracula.txt\n",
      "Found .txt books: 6\n",
      "First few: ['books\\\\alice_in_wonderland.txt', 'books\\\\dracula.txt', 'books\\\\frankenstein.txt']\n",
      "  alice_in_wonderland.txt: 137 passages\n",
      "  dracula.txt: 250 passages\n",
      "  frankenstein.txt: 250 passages\n",
      "  moby_dick.txt: 250 passages\n",
      "  pride_and_prejudice.txt: 250 passages\n",
      "  sherlock_holmes.txt: 250 passages\n",
      "Total passages: 1387\n",
      "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 22/22 [00:01<00:00, 16.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: (1387, 384)  time=1.4s\n",
      "DTDR (single) built: q=(1387, 512) scales=(1387, 32) blocks=32  tf=('hadamard',)\n",
      "DTDR (double) built: q=(1387, 512) scales=(1387, 32) blocks=32  tf=('hadamard', 'dct')  (DCT=yes)\n",
      "\n",
      "RAG metrics (clean):\n",
      "single: {'mode': 'single_clean', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "double: {'mode': 'double_clean', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "\n",
      "Corruption sweep (dropout) — SINGLE vs DOUBLE:\n",
      "0.0 single {'mode': 'single_dropout_0.0', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_dropout_0.0', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.01 single {'mode': 'single_dropout_0.01', 'K': 8.0, 'mean_overlap_vs_float': 0.9375, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_dropout_0.01', 'K': 8.0, 'mean_overlap_vs_float': 0.9791666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.05 single {'mode': 'single_dropout_0.05', 'K': 8.0, 'mean_overlap_vs_float': 0.8541666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_dropout_0.05', 'K': 8.0, 'mean_overlap_vs_float': 0.8541666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.1 single {'mode': 'single_dropout_0.1', 'K': 8.0, 'mean_overlap_vs_float': 0.75, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_dropout_0.1', 'K': 8.0, 'mean_overlap_vs_float': 0.8333333333333334, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.2 single {'mode': 'single_dropout_0.2', 'K': 8.0, 'mean_overlap_vs_float': 0.7708333333333334, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_dropout_0.2', 'K': 8.0, 'mean_overlap_vs_float': 0.75, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "\n",
      "Corruption sweep (block loss) — SINGLE vs DOUBLE:\n",
      "0.0 single {'mode': 'single_blockloss_0.0', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_blockloss_0.0', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.01 single {'mode': 'single_blockloss_0.01', 'K': 8.0, 'mean_overlap_vs_float': 0.9375, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_blockloss_0.01', 'K': 8.0, 'mean_overlap_vs_float': 0.9583333333333334, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.05 single {'mode': 'single_blockloss_0.05', 'K': 8.0, 'mean_overlap_vs_float': 0.9375, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_blockloss_0.05', 'K': 8.0, 'mean_overlap_vs_float': 0.9791666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.1 single {'mode': 'single_blockloss_0.1', 'K': 8.0, 'mean_overlap_vs_float': 0.875, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_blockloss_0.1', 'K': 8.0, 'mean_overlap_vs_float': 0.9583333333333334, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.2 single {'mode': 'single_blockloss_0.2', 'K': 8.0, 'mean_overlap_vs_float': 0.8541666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0} double {'mode': 'double_blockloss_0.2', 'K': 8.0, 'mean_overlap_vs_float': 0.9166666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "\n",
      "============================================================================================\n",
      "SINGLE DTDR (clean)\n",
      "QUESTION: Who is the White Rabbit and what is he doing?\n",
      "Expected: alice_in_wonderland.txt | Anchors: ['white rabbit', 'rabbit']\n",
      "--------------------------------------------------------------------------------------------\n",
      " 1. alice_in_wonderland.txt [chunk 30]\n",
      "n a melancholy tone. “Nobody seems to like her, down here, and I’m sure she’s the best cat in the world! Oh, my dear Dinah! I wonder if I shall ever see you any more!” And here poor Alice began to cry again, for she felt very lonely and low-spirited. In a …\n",
      "\n",
      " 2. alice_in_wonderland.txt [chunk 85]\n",
      "“That’s right!” shouted the Queen. “Can you play croquet?” The soldiers were silent, and looked at Alice, as the question was evidently meant for her. “Yes!” shouted Alice. “Come on, then!” roared the Queen, and Alice joined the procession, wondering very …\n",
      "\n",
      " 3. alice_in_wonderland.txt [chunk 5]\n",
      "ither question, it didn’t much matter which way she put it. She felt that she was dozing off, and had just begun to dream that she was walking hand in hand with Dinah, and saying to her very earnestly, “Now, Dinah, tell me the truth: did you ever eat a bat?” …\n",
      "\n",
      " 4. alice_in_wonderland.txt [chunk 13]\n",
      "hing half down the hall. After a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming. It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large …\n",
      "\n",
      " 5. alice_in_wonderland.txt [chunk 118]\n",
      "the jurors had a pencil that squeaked. This of course, Alice could _not_ stand, and she went round the court and got behind him, and very soon found an opportunity of taking it away. She did it so quickly that the poor little juror (it was Bill, the Lizard) …\n",
      "\n",
      "RAG PROMPT (example):\n",
      "--------------------------------------------------------------------------------------------\n",
      "Question: Who is the White Rabbit and what is he doing?\n",
      "Context:\n",
      " n a melancholy tone. “Nobody seems to like her, down here, and I’m sure she’s the best cat in the world! Oh, my dear Dinah! I wonder if I shall ever see you any more!” And here poor Alice began to cry again, for she felt very lonely and low-spirited. In a little while, however, she again heard a little pattering of footsteps in the distance, and she looked up eagerly, half hoping that the Mouse had changed his mind, and was coming back to finish his story. CHAPTER IV. The Rabbit Sends in a Little Bill It was the White Rabbit, trotting slowly back again, and looking anxiously about as it went, as if it had lost something; and she heard it …\n",
      "\n",
      "============================================================================================\n",
      "DOUBLE/COMPOSITE DTDR (clean)  (DCT=yes)\n",
      "QUESTION: Who is the White Rabbit and what is he doing?\n",
      "Expected: alice_in_wonderland.txt | Anchors: ['white rabbit', 'rabbit']\n",
      "--------------------------------------------------------------------------------------------\n",
      " 1. alice_in_wonderland.txt [chunk 30]\n",
      "n a melancholy tone. “Nobody seems to like her, down here, and I’m sure she’s the best cat in the world! Oh, my dear Dinah! I wonder if I shall ever see you any more!” And here poor Alice began to cry again, for she felt very lonely and low-spirited. In a …\n",
      "\n",
      " 2. alice_in_wonderland.txt [chunk 85]\n",
      "“That’s right!” shouted the Queen. “Can you play croquet?” The soldiers were silent, and looked at Alice, as the question was evidently meant for her. “Yes!” shouted Alice. “Come on, then!” roared the Queen, and Alice joined the procession, wondering very …\n",
      "\n",
      " 3. alice_in_wonderland.txt [chunk 5]\n",
      "ither question, it didn’t much matter which way she put it. She felt that she was dozing off, and had just begun to dream that she was walking hand in hand with Dinah, and saying to her very earnestly, “Now, Dinah, tell me the truth: did you ever eat a bat?” …\n",
      "\n",
      " 4. alice_in_wonderland.txt [chunk 13]\n",
      "hing half down the hall. After a time she heard a little pattering of feet in the distance, and she hastily dried her eyes to see what was coming. It was the White Rabbit returning, splendidly dressed, with a pair of white kid gloves in one hand and a large …\n",
      "\n",
      " 5. alice_in_wonderland.txt [chunk 118]\n",
      "the jurors had a pencil that squeaked. This of course, Alice could _not_ stand, and she went round the court and got behind him, and very soon found an opportunity of taking it away. She did it so quickly that the poor little juror (it was Bill, the Lizard) …\n",
      "\n",
      "RAG PROMPT (example):\n",
      "--------------------------------------------------------------------------------------------\n",
      "Question: Who is the White Rabbit and what is he doing?\n",
      "Context:\n",
      " n a melancholy tone. “Nobody seems to like her, down here, and I’m sure she’s the best cat in the world! Oh, my dear Dinah! I wonder if I shall ever see you any more!” And here poor Alice began to cry again, for she felt very lonely and low-spirited. In a little while, however, she again heard a little pattering of footsteps in the distance, and she looked up eagerly, half hoping that the Mouse had changed his mind, and was coming back to finish his story. CHAPTER IV. The Rabbit Sends in a Little Bill It was the White Rabbit, trotting slowly back again, and looking anxiously about as it went, as if it had lost something; and she heard it …\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Single-cell DTDR + \"Double\" Composite-DTDR RAG Experiment\n",
    "# --------------------------------------------------------\n",
    "# Demonstrates: DTDR is a computational representation (compute + retrieval in transform domain),\n",
    "# and that composing orthogonal transforms (e.g., Hadamard then DCT) still supports high-quality RAG retrieval.\n",
    "#\n",
    "# Requires: sentence-transformers, numpy. (scipy optional; used for DCT if available)\n",
    "\n",
    "# ---- Environment bootstrap (safe re-run) ----\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "FAST_MODE = True\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def ensure(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "required = [\"numpy\", \"scipy\", \"matplotlib\", \"scikit-learn\", \"requests\"]\n",
    "for r in required:\n",
    "    try:\n",
    "        __import__(r)\n",
    "    except ImportError:\n",
    "        ensure(r)\n",
    "\n",
    "import os, re, math, time, random, textwrap, urllib.request\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import hadamard\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Optional DCT\n",
    "try:\n",
    "    from scipy.fft import dct as scipy_dct\n",
    "    HAVE_DCT = True\n",
    "except Exception:\n",
    "    HAVE_DCT = False\n",
    "\n",
    "SEED = 123\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BOOKS_DIR = \"books\"\n",
    "os.makedirs(BOOKS_DIR, exist_ok=True)\n",
    "\n",
    "GUTENBERG = [\n",
    "    (\"alice_in_wonderland.txt\", \"https://www.gutenberg.org/cache/epub/11/pg11.txt\"),\n",
    "    (\"pride_and_prejudice.txt\", \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"),\n",
    "    (\"frankenstein.txt\", \"https://www.gutenberg.org/cache/epub/84/pg84.txt\"),\n",
    "    (\"moby_dick.txt\", \"https://www.gutenberg.org/cache/epub/2701/pg2701.txt\"),\n",
    "    (\"sherlock_holmes.txt\", \"https://www.gutenberg.org/cache/epub/1661/pg1661.txt\"),\n",
    "    (\"dracula.txt\", \"https://www.gutenberg.org/cache/epub/345/pg345.txt\"),\n",
    "]\n",
    "\n",
    "def download(url: str, path: str, timeout: int = 30) -> bool:\n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
    "        with urllib.request.urlopen(req, timeout=timeout) as resp:\n",
    "            data = resp.read()\n",
    "        try:\n",
    "            txt = data.decode(\"utf-8\")\n",
    "        except UnicodeDecodeError:\n",
    "            txt = data.decode(\"latin-1\")\n",
    "        with open(path, \"w\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            f.write(txt)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Download failed: {url} ({e})\")\n",
    "        return False\n",
    "\n",
    "def read_text_file(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def clean_gutenberg(text: str) -> str:\n",
    "    start = re.search(r\"\\*\\*\\*\\s*START OF (THIS|THE) PROJECT GUTENBERG\", text, flags=re.IGNORECASE)\n",
    "    end   = re.search(r\"\\*\\*\\*\\s*END OF (THIS|THE) PROJECT GUTENBERG\", text, flags=re.IGNORECASE)\n",
    "    if start and end and start.end() < end.start():\n",
    "        text = text[start.end():end.start()]\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def chunk_text(text: str, chunk_chars: int = 1200, overlap: int = 150, min_len: int = 250) -> List[str]:\n",
    "    chunks = []\n",
    "    step = max(1, chunk_chars - overlap)\n",
    "    for i in range(0, len(text), step):\n",
    "        ch = text[i:i+chunk_chars].strip()\n",
    "        if len(ch) >= min_len:\n",
    "            chunks.append(ch)\n",
    "    return chunks\n",
    "\n",
    "print(\"Books directory:\", os.path.abspath(BOOKS_DIR))\n",
    "for fname, url in GUTENBERG:\n",
    "    path = os.path.join(BOOKS_DIR, fname)\n",
    "    if not os.path.exists(path) or os.path.getsize(path) < 2000:\n",
    "        print(\"Downloading:\", fname)\n",
    "        download(url, path)\n",
    "\n",
    "book_paths = [os.path.join(BOOKS_DIR, fn) for fn in os.listdir(BOOKS_DIR) if fn.lower().endswith(\".txt\")]\n",
    "book_paths.sort()\n",
    "\n",
    "# Filter to just our Gutenberg list (and skip demo_book_*.txt)\n",
    "include_books = {fn for fn, _ in GUTENBERG}\n",
    "book_paths = [p for p in book_paths if os.path.basename(p) in include_books]\n",
    "\n",
    "print(\"Found .txt books:\", len(book_paths))\n",
    "print(\"First few:\", book_paths[:3])\n",
    "\n",
    "@dataclass\n",
    "class Passage:\n",
    "    book: str\n",
    "    idx: int\n",
    "    text: str\n",
    "\n",
    "def build_passages(paths: List[str], chunk_chars=1200, overlap=150, max_passages_per_book=250) -> List[Passage]:\n",
    "    out: List[Passage] = []\n",
    "    for p in paths:\n",
    "        bn = os.path.basename(p)\n",
    "        raw = read_text_file(p)\n",
    "        txt = clean_gutenberg(raw)\n",
    "        chunks = chunk_text(txt, chunk_chars=chunk_chars, overlap=overlap, min_len=250)\n",
    "        chunks = chunks[:max_passages_per_book]\n",
    "        print(f\"  {bn}: {len(chunks)} passages\")\n",
    "        for i, ch in enumerate(chunks):\n",
    "            out.append(Passage(book=bn, idx=i, text=ch))\n",
    "    return out\n",
    "\n",
    "passages = build_passages(book_paths, chunk_chars=1200, overlap=150, max_passages_per_book=250)\n",
    "texts = [p.text for p in passages]\n",
    "books = [p.book for p in passages]\n",
    "print(\"Total passages:\", len(passages))\n",
    "assert len(passages) > 200, \"Too few passages; increase max_passages_per_book.\"\n",
    "\n",
    "# ---------------- Embeddings ----------------\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "print(\"Loading embedding model:\", MODEL_NAME)\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "t0 = time.time()\n",
    "emb = model.encode(texts, batch_size=64, show_progress_bar=True, normalize_embeddings=True)\n",
    "emb = np.asarray(emb, dtype=np.float32)\n",
    "t1 = time.time()\n",
    "print(f\"Embeddings: {emb.shape}  time={t1-t0:.1f}s\")\n",
    "\n",
    "# ---------------- DTDR core ----------------\n",
    "def next_pow2(n: int) -> int:\n",
    "    return 1 if n <= 1 else 2 ** int(math.ceil(math.log2(n)))\n",
    "\n",
    "def make_hadamard(n: int) -> np.ndarray:\n",
    "    H = hadamard(n).astype(np.float32)\n",
    "    H /= np.sqrt(n)\n",
    "    return H\n",
    "\n",
    "def pad_to_dh(X: np.ndarray, d_h: int) -> np.ndarray:\n",
    "    N, d = X.shape\n",
    "    if d == d_h:\n",
    "        return X\n",
    "    out = np.zeros((N, d_h), dtype=X.dtype)\n",
    "    out[:, :d] = X\n",
    "    return out\n",
    "\n",
    "def quantize_blockwise(U: np.ndarray, block: int = 16) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    # int8 symmetric per-block scaling\n",
    "    N, D = U.shape\n",
    "    nblocks = (D + block - 1) // block\n",
    "    qmax = 127\n",
    "    q = np.zeros((N, D), dtype=np.int8)\n",
    "    scales = np.zeros((N, nblocks), dtype=np.float32)\n",
    "    for b in range(nblocks):\n",
    "        j0, j1 = b*block, min(D, (b+1)*block)\n",
    "        chunk = U[:, j0:j1]\n",
    "        amax = np.max(np.abs(chunk), axis=1) + 1e-12\n",
    "        s = amax / qmax\n",
    "        scales[:, b] = s\n",
    "        q[:, j0:j1] = np.clip(np.round(chunk / s[:, None]), -qmax, qmax).astype(np.int8)\n",
    "    return q, scales\n",
    "\n",
    "def apply_transform_vector(v: np.ndarray, kind: str, H: np.ndarray) -> np.ndarray:\n",
    "    if kind == \"hadamard\":\n",
    "        return (H @ v).astype(np.float32)\n",
    "    if kind == \"dct\":\n",
    "        if not HAVE_DCT:\n",
    "            # fallback: use another Hadamard instead (still orthogonal)\n",
    "            return (H @ v).astype(np.float32)\n",
    "        return scipy_dct(v.astype(np.float32), norm=\"ortho\").astype(np.float32)\n",
    "    raise ValueError(\"Unknown transform kind:\", kind)\n",
    "\n",
    "def apply_transform_matrix(X: np.ndarray, kind: str, H: np.ndarray) -> np.ndarray:\n",
    "    if kind == \"hadamard\":\n",
    "        return (X @ H.T).astype(np.float32)\n",
    "    if kind == \"dct\":\n",
    "        if not HAVE_DCT:\n",
    "            return (X @ H.T).astype(np.float32)\n",
    "        # DCT along last axis for each row\n",
    "        return scipy_dct(X.astype(np.float32), axis=1, norm=\"ortho\").astype(np.float32)\n",
    "    raise ValueError(\"Unknown transform kind:\", kind)\n",
    "\n",
    "def build_dtdr(X: np.ndarray, H: np.ndarray, block: int, transforms: Tuple[str, ...]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    U = X\n",
    "    for tkind in transforms:\n",
    "        U = apply_transform_matrix(U, tkind, H)\n",
    "    qcoef, scales = quantize_blockwise(U, block=block)\n",
    "    return qcoef, scales\n",
    "\n",
    "def dt_scores(qemb: np.ndarray, qcoef: np.ndarray, scales: np.ndarray, H: np.ndarray, block: int, transforms: Tuple[str, ...]) -> np.ndarray:\n",
    "    # build query transform-domain vector\n",
    "    v = qemb.astype(np.float32)\n",
    "    # assume v already padded to d_h outside (caller)\n",
    "    for tkind in transforms:\n",
    "        v = apply_transform_vector(v, tkind, H)\n",
    "    qf = qcoef.astype(np.float32)\n",
    "    sf = scales.astype(np.float32)\n",
    "    out = np.zeros((qf.shape[0],), dtype=np.float32)\n",
    "    nblocks = sf.shape[1]\n",
    "    for b in range(nblocks):\n",
    "        j0, j1 = b*block, min(qf.shape[1], (b+1)*block)\n",
    "        out += (qf[:, j0:j1] * v[j0:j1]).sum(axis=1) * sf[:, b]\n",
    "    return out\n",
    "\n",
    "def topk(scores: np.ndarray, k: int) -> np.ndarray:\n",
    "    k = int(k)\n",
    "    if k >= scores.shape[0]:\n",
    "        return np.argsort(-scores)\n",
    "    idx = np.argpartition(-scores, k)[:k]\n",
    "    return idx[np.argsort(-scores[idx])]\n",
    "\n",
    "# Parameters\n",
    "BLOCK = 16\n",
    "d_in = emb.shape[1]\n",
    "d_h = next_pow2(d_in)\n",
    "H = make_hadamard(d_h)\n",
    "X = pad_to_dh(emb, d_h)\n",
    "\n",
    "# Single DTDR = Hadamard\n",
    "single_tf = (\"hadamard\",)\n",
    "q_single, s_single = build_dtdr(X, H, BLOCK, single_tf)\n",
    "\n",
    "# \"Double\" Composite DTDR = Hadamard then DCT (or Hadamard fallback if no DCT)\n",
    "double_tf = (\"hadamard\", \"dct\")\n",
    "q_double, s_double = build_dtdr(X, H, BLOCK, double_tf)\n",
    "\n",
    "print(f\"DTDR (single) built: q={q_single.shape} scales={s_single.shape} blocks={s_single.shape[1]}  tf={single_tf}\")\n",
    "print(f\"DTDR (double) built: q={q_double.shape} scales={s_double.shape} blocks={s_double.shape[1]}  tf={double_tf}  (DCT={'yes' if HAVE_DCT else 'no-fallback'})\")\n",
    "\n",
    "# Float baseline for overlap\n",
    "def float_scores(qemb_small: np.ndarray) -> np.ndarray:\n",
    "    return emb @ qemb_small.astype(np.float32)\n",
    "\n",
    "# ---------------- RAG-style queries ----------------\n",
    "RAG_QUERIES = [\n",
    "    (\"Who is the White Rabbit and what is he doing?\", \"alice_in_wonderland.txt\", [\"white rabbit\", \"rabbit\"]),\n",
    "    (\"What does Elizabeth think of Mr. Darcy early on?\", \"pride_and_prejudice.txt\", [\"darcy\", \"elizabeth\"]),\n",
    "    (\"Who created the creature and what was the consequence?\", \"frankenstein.txt\", [\"frankenstein\", \"creature\"]),\n",
    "    (\"What is Captain Ahab obsessed with?\", \"moby_dick.txt\", [\"ahab\", \"whale\"]),\n",
    "    (\"What is Sherlock Holmes known for in solving mysteries?\", \"sherlock_holmes.txt\", [\"holmes\", \"watson\"]),\n",
    "    (\"Who is Count Dracula and what is his nature?\", \"dracula.txt\", [\"dracula\", \"count\"]),\n",
    "]\n",
    "\n",
    "norm_passages = [re.sub(r\"\\s+\", \" \", t.lower()) for t in texts]\n",
    "\n",
    "def book_hit_at_k(idxs: np.ndarray, expected_book: str) -> int:\n",
    "    return int(any(books[i] == expected_book for i in idxs))\n",
    "\n",
    "def anchor_hit_at_k(idxs: np.ndarray, anchors: List[str]) -> int:\n",
    "    anchors_l = [a.lower() for a in anchors]\n",
    "    for i in idxs:\n",
    "        t = norm_passages[i]\n",
    "        if any(a in t for a in anchors_l):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def eval_rag(qcoef: np.ndarray, scales: np.ndarray, transforms: Tuple[str, ...], label: str, K: int = 8) -> Dict[str, float]:\n",
    "    overlaps, bookhits, anchorhits = [], [], []\n",
    "    for q, exp_book, anchors in RAG_QUERIES:\n",
    "        qemb_small = model.encode([q], normalize_embeddings=True)[0].astype(np.float32)\n",
    "        base = topk(float_scores(qemb_small), K)\n",
    "\n",
    "        qpad = np.zeros((d_h,), dtype=np.float32)\n",
    "        qpad[:d_in] = qemb_small\n",
    "        dt = topk(dt_scores(qpad, qcoef, scales, H, BLOCK, transforms), K)\n",
    "\n",
    "        overlaps.append(len(set(base.tolist()).intersection(set(dt.tolist()))) / len(base))\n",
    "        bookhits.append(book_hit_at_k(dt, exp_book))\n",
    "        anchorhits.append(anchor_hit_at_k(dt, anchors))\n",
    "    return {\n",
    "        \"mode\": label,\n",
    "        \"K\": float(K),\n",
    "        \"mean_overlap_vs_float\": float(np.mean(overlaps)),\n",
    "        \"book_hit_rate@K\": float(np.mean(bookhits)),\n",
    "        \"anchor_hit_rate@K\": float(np.mean(anchorhits)),\n",
    "    }\n",
    "\n",
    "print(\"\\nRAG metrics (clean):\")\n",
    "print(\"single:\", eval_rag(q_single, s_single, single_tf, \"single_clean\", K=8))\n",
    "print(\"double:\", eval_rag(q_double, s_double, double_tf, \"double_clean\", K=8))\n",
    "\n",
    "# ---------------- Corruption ----------------\n",
    "def corrupt_dropout(q: np.ndarray, drop_frac: float, seed: int = 123) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    out = q.copy()\n",
    "    mask = rng.random(out.shape) < drop_frac\n",
    "    out[mask] = 0\n",
    "    return out\n",
    "\n",
    "def corrupt_block_loss(q: np.ndarray, block_frac: float, seed: int = 123) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    out = q.copy()\n",
    "    Nn, D = out.shape\n",
    "    nblocks = (D + BLOCK - 1) // BLOCK\n",
    "    if block_frac <= 0:\n",
    "        return out\n",
    "    n_drop = max(1, int(math.ceil(block_frac * nblocks)))\n",
    "    drop_blocks = rng.choice(nblocks, size=min(nblocks, n_drop), replace=False)\n",
    "    for b in drop_blocks:\n",
    "        j0, j1 = b*BLOCK, min(D, (b+1)*BLOCK)\n",
    "        out[:, j0:j1] = 0\n",
    "    return out\n",
    "\n",
    "levels = [0.0, 0.01, 0.05, 0.10, 0.20]\n",
    "\n",
    "print(\"\\nCorruption sweep (dropout) — SINGLE vs DOUBLE:\")\n",
    "for lvl in levels:\n",
    "    qs = corrupt_dropout(q_single, lvl, seed=SEED)\n",
    "    qd = corrupt_dropout(q_double, lvl, seed=SEED)\n",
    "    print(lvl,\n",
    "          \"single\", eval_rag(qs, s_single, single_tf, f\"single_dropout_{lvl}\", K=8),\n",
    "          \"double\", eval_rag(qd, s_double, double_tf, f\"double_dropout_{lvl}\", K=8))\n",
    "\n",
    "print(\"\\nCorruption sweep (block loss) — SINGLE vs DOUBLE:\")\n",
    "for lvl in levels:\n",
    "    qs = corrupt_block_loss(q_single, lvl, seed=SEED)\n",
    "    qd = corrupt_block_loss(q_double, lvl, seed=SEED)\n",
    "    print(lvl,\n",
    "          \"single\", eval_rag(qs, s_single, single_tf, f\"single_blockloss_{lvl}\", K=8),\n",
    "          \"double\", eval_rag(qd, s_double, double_tf, f\"double_blockloss_{lvl}\", K=8))\n",
    "\n",
    "# ---------------- Show example prompts ----------------\n",
    "def show_example(question: str, expected_book: str, anchors: List[str],\n",
    "                 qcoef: np.ndarray, scales: np.ndarray, transforms: Tuple[str, ...],\n",
    "                 title: str, K: int = 5):\n",
    "    qemb_small = model.encode([question], normalize_embeddings=True)[0].astype(np.float32)\n",
    "    qpad = np.zeros((d_h,), dtype=np.float32)\n",
    "    qpad[:d_in] = qemb_small\n",
    "    idx = topk(dt_scores(qpad, qcoef, scales, H, BLOCK, transforms), K)\n",
    "    print(\"\\n\" + \"=\"*92)\n",
    "    print(title)\n",
    "    print(\"QUESTION:\", question)\n",
    "    print(\"Expected:\", expected_book, \"| Anchors:\", anchors)\n",
    "    print(\"-\"*92)\n",
    "    for r, i in enumerate(idx, 1):\n",
    "        ps = passages[i]\n",
    "        print(f\"{r:>2}. {ps.book} [chunk {ps.idx}]\")\n",
    "        print(textwrap.shorten(ps.text.replace(\"\\n\",\" \"), width=260, placeholder=\" …\"))\n",
    "        print()\n",
    "    context = \"\\n\\n\".join([passages[i].text for i in idx[:min(3, len(idx))]])\n",
    "    print(\"RAG PROMPT (example):\")\n",
    "    print(\"-\"*92)\n",
    "    print(\"Question:\", question)\n",
    "    print(\"Context:\\n\", textwrap.shorten(context.replace(\"\\n\",\" \"), width=650, placeholder=\" …\"))\n",
    "\n",
    "q0, exp0, anc0 = RAG_QUERIES[0]\n",
    "show_example(q0, exp0, anc0, q_single, s_single, single_tf, title=\"SINGLE DTDR (clean)\", K=5)\n",
    "show_example(q0, exp0, anc0, q_double, s_double, double_tf, title=f\"DOUBLE/COMPOSITE DTDR (clean)  (DCT={'yes' if HAVE_DCT else 'fallback'})\", K=5)\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488e6ce3-1848-4aeb-850a-ecb172a0e761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO-TRANSFORM INT8 built: q=(1387, 512) scales=(1387, 32) blocks=32\n",
      "\n",
      "RAG metrics (clean) — No-transform INT8:\n",
      "{'mode': 'raw_clean', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "\n",
      "Corruption sweep (dropout) — No-transform INT8:\n",
      "0.0 {'mode': 'raw_dropout_0.0', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.01 {'mode': 'raw_dropout_0.01', 'K': 8.0, 'mean_overlap_vs_float': 0.9375, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.05 {'mode': 'raw_dropout_0.05', 'K': 8.0, 'mean_overlap_vs_float': 0.8541666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.1 {'mode': 'raw_dropout_0.1', 'K': 8.0, 'mean_overlap_vs_float': 0.8125, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.2 {'mode': 'raw_dropout_0.2', 'K': 8.0, 'mean_overlap_vs_float': 0.6666666666666666, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "\n",
      "Corruption sweep (block loss) — No-transform INT8:\n",
      "0.0 {'mode': 'raw_blockloss_0.0', 'K': 8.0, 'mean_overlap_vs_float': 1.0, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.01 {'mode': 'raw_blockloss_0.01', 'K': 8.0, 'mean_overlap_vs_float': 0.9375, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.05 {'mode': 'raw_blockloss_0.05', 'K': 8.0, 'mean_overlap_vs_float': 0.9375, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.1 {'mode': 'raw_blockloss_0.1', 'K': 8.0, 'mean_overlap_vs_float': 0.8958333333333334, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "0.2 {'mode': 'raw_blockloss_0.2', 'K': 8.0, 'mean_overlap_vs_float': 0.875, 'book_hit_rate@K': 1.0, 'anchor_hit_rate@K': 1.0}\n",
      "\n",
      "Done (ablation).\n"
     ]
    }
   ],
   "source": [
    "# Ablation / Negative Control: \"No-transform INT8\" vs DTDR\n",
    "# -------------------------------------------------------\n",
    "# Purpose: show that the transform step is not incidental.\n",
    "# We quantize the *raw* embedding vectors directly (no orthogonal transform),\n",
    "# then do dot-product similarity in the same \"quantized-domain\" way.\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# --- helper: blockwise quantize already defined above? If not, redefine minimal version here.\n",
    "def quantize_blockwise_raw(U: np.ndarray, block: int = 16):\n",
    "    N, D = U.shape\n",
    "    nblocks = (D + block - 1) // block\n",
    "    qmax = 127\n",
    "    q = np.zeros((N, D), dtype=np.int8)\n",
    "    scales = np.zeros((N, nblocks), dtype=np.float32)\n",
    "    for b in range(nblocks):\n",
    "        j0, j1 = b*block, min(D, (b+1)*block)\n",
    "        chunk = U[:, j0:j1]\n",
    "        amax = np.max(np.abs(chunk), axis=1) + 1e-12\n",
    "        s = amax / qmax\n",
    "        scales[:, b] = s\n",
    "        q[:, j0:j1] = np.clip(np.round(chunk / s[:, None]), -qmax, qmax).astype(np.int8)\n",
    "    return q, scales\n",
    "\n",
    "def scores_quantized_no_transform(qpad: np.ndarray, qcoef: np.ndarray, scales: np.ndarray, block: int):\n",
    "    # qpad is already length d_h (padded)\n",
    "    qf = qcoef.astype(np.float32)\n",
    "    sf = scales.astype(np.float32)\n",
    "    out = np.zeros((qf.shape[0],), dtype=np.float32)\n",
    "    nblocks = sf.shape[1]\n",
    "    for b in range(nblocks):\n",
    "        j0, j1 = b*block, min(qf.shape[1], (b+1)*block)\n",
    "        out += (qf[:, j0:j1] * qpad[j0:j1]).sum(axis=1) * sf[:, b]\n",
    "    return out\n",
    "\n",
    "# reuse these from your prior cell\n",
    "# BLOCK, d_h, d_in, emb, model, topk, float_scores, passages, books, norm_passages, RAG_QUERIES\n",
    "\n",
    "# Build \"no-transform\" representation: quantize padded embeddings directly\n",
    "X_raw = np.zeros((emb.shape[0], d_h), dtype=np.float32)\n",
    "X_raw[:, :d_in] = emb.astype(np.float32)\n",
    "\n",
    "q_raw, s_raw = quantize_blockwise_raw(X_raw, block=BLOCK)\n",
    "print(f\"NO-TRANSFORM INT8 built: q={q_raw.shape} scales={s_raw.shape} blocks={s_raw.shape[1]}\")\n",
    "\n",
    "def eval_rag_no_transform(qcoef: np.ndarray, scales: np.ndarray, label: str, K: int = 8):\n",
    "    overlaps, bookhits, anchorhits = [], [], []\n",
    "    for q, exp_book, anchors in RAG_QUERIES:\n",
    "        qemb_small = model.encode([q], normalize_embeddings=True)[0].astype(np.float32)\n",
    "        base = topk(float_scores(qemb_small), K)\n",
    "\n",
    "        qpad = np.zeros((d_h,), dtype=np.float32)\n",
    "        qpad[:d_in] = qemb_small\n",
    "        dt = topk(scores_quantized_no_transform(qpad, qcoef, scales, BLOCK), K)\n",
    "\n",
    "        overlaps.append(len(set(base.tolist()).intersection(set(dt.tolist()))) / len(base))\n",
    "        bookhits.append(int(any(books[i] == exp_book for i in dt)))\n",
    "        anchors_l = [a.lower() for a in anchors]\n",
    "        anchorhits.append(int(any(any(a in norm_passages[i] for a in anchors_l) for i in dt)))\n",
    "    return {\n",
    "        \"mode\": label,\n",
    "        \"K\": float(K),\n",
    "        \"mean_overlap_vs_float\": float(np.mean(overlaps)),\n",
    "        \"book_hit_rate@K\": float(np.mean(bookhits)),\n",
    "        \"anchor_hit_rate@K\": float(np.mean(anchorhits)),\n",
    "    }\n",
    "\n",
    "print(\"\\nRAG metrics (clean) — No-transform INT8:\")\n",
    "print(eval_rag_no_transform(q_raw, s_raw, \"raw_clean\", K=8))\n",
    "\n",
    "# Corruption utilities (reuse if present, else define)\n",
    "def corrupt_dropout(q: np.ndarray, drop_frac: float, seed: int = 123) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    out = q.copy()\n",
    "    mask = rng.random(out.shape) < drop_frac\n",
    "    out[mask] = 0\n",
    "    return out\n",
    "\n",
    "def corrupt_block_loss(q: np.ndarray, block_frac: float, seed: int = 123) -> np.ndarray:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    out = q.copy()\n",
    "    Nn, D = out.shape\n",
    "    nblocks = (D + BLOCK - 1) // BLOCK\n",
    "    if block_frac <= 0:\n",
    "        return out\n",
    "    n_drop = max(1, int(math.ceil(block_frac * nblocks)))\n",
    "    drop_blocks = rng.choice(nblocks, size=min(nblocks, n_drop), replace=False)\n",
    "    for b in drop_blocks:\n",
    "        j0, j1 = b*BLOCK, min(D, (b+1)*BLOCK)\n",
    "        out[:, j0:j1] = 0\n",
    "    return out\n",
    "\n",
    "levels = [0.0, 0.01, 0.05, 0.10, 0.20]\n",
    "\n",
    "print(\"\\nCorruption sweep (dropout) — No-transform INT8:\")\n",
    "for lvl in levels:\n",
    "    qr = corrupt_dropout(q_raw, lvl, seed=SEED)\n",
    "    print(lvl, eval_rag_no_transform(qr, s_raw, f\"raw_dropout_{lvl}\", K=8))\n",
    "\n",
    "print(\"\\nCorruption sweep (block loss) — No-transform INT8:\")\n",
    "for lvl in levels:\n",
    "    qr = corrupt_block_loss(q_raw, lvl, seed=SEED)\n",
    "    print(lvl, eval_rag_no_transform(qr, s_raw, f\"raw_blockloss_{lvl}\", K=8))\n",
    "\n",
    "print(\"\\nDone (ablation).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9c355-7c73-42ca-9ec8-b6191719da44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
